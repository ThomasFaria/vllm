nameOverride: ""
fullnameOverride: "llm-serving"
podAnnotations: {}

deployment:
  image:
    repository: vllm/vllm-openai
    pullPolicy: Always
    tag: latest
  hftoken: your_token
  args: 
    model: microsoft/Phi-3-mini-4k-instruct # Phi-3-mini-4k-instruct
    memoryutilization: 0.8
    dtype: half
    maxModelLen: 8208
  gpu:
    number: 1

service:
  port:
    number: 8000
    nodePort: 30501


ingress:
    enabled: true
    className: "nginx"
    annotations: 
      nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    hostname: "llm-serving.example.com"

s3:
  enabled: false # Set to true to use S3
  bucket: "your_bucket_name"
  modelPath: "path_to_model"
  # If not set and create is true, a name is generated using the fullname template
  accessKeyId: "$AWS_ACCESS_KEY_ID" #$AWS_ACCESS_KEY_ID
  endpoint: "$AWS_S3_ENDPOINT" #$AWS_S3_ENDPOINT
  defaultRegion: "$AWS_DEFAULT_REGION" #$AWS_DEFAULT_REGION
  secretAccessKey: "$AWS_SECRET_ACCESS_KEY" #$AWS_SECRET_ACCESS_KEY
  sessionToken: "$AWS_SESSION_TOKEN" #$AWS_SESSION_TOKEN